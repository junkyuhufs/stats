{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNBVU8Y5C5gUMn5AAn24oUa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junkyuhufs/stats/blob/main/WoS_text_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##í…ìŠ¤íŠ¸íŒŒì¼ í•©ì¹˜ê¸°"
      ],
      "metadata": {
        "id": "mlHyTQTkpruD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sM1CCC0appUb"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "# ğŸ”¹ íŒŒì¼ ì—¬ëŸ¬ ê°œ ì—…ë¡œë“œ\n",
        "uploaded = files.upload()\n",
        "\n",
        "# ğŸ”¹ íŒŒì¼ ë‚´ìš©ì„ ë³‘í•©í•  ë¦¬ìŠ¤íŠ¸\n",
        "merged_lines = []\n",
        "\n",
        "# ğŸ”¹ ì—…ë¡œë“œëœ ëª¨ë“  íŒŒì¼ì„ ìˆœì„œëŒ€ë¡œ ë³‘í•©\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"ğŸ“„ ì²˜ë¦¬ ì¤‘: {filename}\")\n",
        "    with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "        merged_lines.extend(f.readlines())\n",
        "        merged_lines.append(\"\\n\")  # íŒŒì¼ ê°„ êµ¬ë¶„ì„ ìœ„í•œ ë¹ˆ ì¤„ ì¶”ê°€ (ì„ íƒ ì‚¬í•­)\n",
        "\n",
        "# ğŸ”¹ ë³‘í•©ëœ íŒŒì¼ ì €ì¥\n",
        "merged_filename = \"merged_output.txt\"\n",
        "with open(merged_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.writelines(merged_lines)\n",
        "\n",
        "print(f\"âœ… ë³‘í•© ì™„ë£Œ: {merged_filename}\")\n",
        "\n",
        "# ğŸ”¹ ë³‘í•©ëœ íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
        "files.download(merged_filename)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DT==Articleë§Œ ë‚¨ê¸°ê¸°"
      ],
      "metadata": {
        "id": "IlQW5ULaroQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 2. ì—…ë¡œë“œëœ íŒŒì¼ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°\n",
        "uploaded_filename = next(iter(uploaded))\n",
        "output_filename = \"1_500_article_only.txt\"\n",
        "\n",
        "# 3. DTê°€ \"Article\"ì¸ ë…¼ë¬¸ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ ì œê±°\n",
        "total_records = 0\n",
        "removed_records = 0\n",
        "filtered_lines = []\n",
        "inside_record = False\n",
        "keep_record = False\n",
        "current_record = []\n",
        "\n",
        "with open(uploaded_filename, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        stripped_line = line.strip()\n",
        "        if stripped_line.startswith(\"PT \"):\n",
        "            total_records += 1\n",
        "            inside_record = True\n",
        "            keep_record = False\n",
        "            current_record = [line]\n",
        "        elif stripped_line.startswith(\"ER\") and inside_record:\n",
        "            current_record.append(line)\n",
        "            inside_record = False\n",
        "            if keep_record:\n",
        "                filtered_lines.extend(current_record)\n",
        "            else:\n",
        "                removed_records += 1\n",
        "        elif inside_record:\n",
        "            current_record.append(line)\n",
        "            if stripped_line.startswith(\"DT \") and stripped_line[3:].strip() == \"Article\":\n",
        "                keep_record = True\n",
        "        else:\n",
        "            filtered_lines.append(line)  # íŒŒì¼ ë§¨ ì•ì´ë‚˜ ëë¶€ë¶„ì— ìˆëŠ” ë¶€ê°€ ì •ë³´\n",
        "\n",
        "# 4. ê²°ê³¼ íŒŒì¼ ì €ì¥\n",
        "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.writelines(filtered_lines)\n",
        "\n",
        "# 5. ê²°ê³¼ ì¶œë ¥\n",
        "print(f\"ì´ ë…¼ë¬¸ ìˆ˜: {total_records}\")\n",
        "print(f\"ì‚­ì œëœ ë…¼ë¬¸ ìˆ˜ (DT != 'Article'): {removed_records}\")\n",
        "print(f\"ë‚¨ì€ ë…¼ë¬¸ ìˆ˜: {total_records - removed_records}\")\n",
        "print(f\"íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_filename}\")\n",
        "\n",
        "# 6. ë‹¤ìš´ë¡œë“œ ë§í¬ ìƒì„±\n",
        "files.download(output_filename)\n"
      ],
      "metadata": {
        "id": "SWRXfyG7rsjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ì°¸ê³ ë¬¸í—Œ ì¤‘ ì €ìë¶ˆë¶„ëª…ì‚­ì œ"
      ],
      "metadata": {
        "id": "TjuehKRtspen"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯ (Colabì—ì„œ íŒŒì¼ ì—…ë¡œë“œ)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# íŒŒì¼ ì´ë¦„ (ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ íŒŒì¼ ì´ë¦„ ìë™ ì¶”ì¶œ)\n",
        "import io\n",
        "\n",
        "uploaded_filename = next(iter(uploaded))\n",
        "file_path = uploaded_filename\n",
        "output_path = \"1_500_no_anonymous_preserve_cr.txt\"\n",
        "\n",
        "# [Anonymous] ë¼ì¸ ì‚­ì œ + CR ë¼ë²¨ ìœ ì§€\n",
        "removed_count = 0\n",
        "cleaned_lines = []\n",
        "inside_cr_section = False\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    for line in f:\n",
        "        stripped_line = line.strip()\n",
        "        if stripped_line.startswith(\"CR\"):\n",
        "            inside_cr_section = True\n",
        "            if \"[Anonymous]\" in stripped_line:\n",
        "                removed_count += 1\n",
        "                cleaned_lines.append(\"CR\\n\")  # CRì€ ìœ ì§€\n",
        "                continue\n",
        "        elif inside_cr_section and stripped_line == \"\":\n",
        "            inside_cr_section = False\n",
        "        elif inside_cr_section:\n",
        "            if \"[Anonymous]\" in stripped_line:\n",
        "                removed_count += 1\n",
        "                continue\n",
        "        cleaned_lines.append(line)\n",
        "\n",
        "# ìƒˆ íŒŒì¼ë¡œ ì €ì¥\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.writelines(cleaned_lines)\n",
        "\n",
        "# ê²°ê³¼ ì¶œë ¥\n",
        "print(f\"[Anonymous] ë¼ì¸ì´ {removed_count}ê°œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
        "print(f\"ì •ë¦¬ëœ íŒŒì¼ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}\")\n",
        "\n",
        "# ê²°ê³¼ì €ì¥\n",
        "files.download(\"1_500_no_anonymous_preserve_cr.txt\")\n"
      ],
      "metadata": {
        "id": "XWQVXf0Hsz-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2025ë…„ ë…¼ë¬¸ì‚­ì œ"
      ],
      "metadata": {
        "id": "c9FtH5X2jKnH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. íŒŒì¼ ì—…ë¡œë“œ\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "filename = list(uploaded.keys())[0]\n",
        "\n",
        "# 2. íŒŒì¼ ì½ê¸°\n",
        "with open(filename, 'r', encoding='utf-8') as f:\n",
        "    data = f.read()\n",
        "\n",
        "# 3. ë…¼ë¬¸ ë¸”ë¡ì„ PT ~ ER ë‹¨ìœ„ë¡œ ë¶„ë¦¬\n",
        "papers = data.split('\\nER\\n')\n",
        "papers = [paper.strip() for paper in papers if paper.strip()]\n",
        "\n",
        "# 4. 'PY 2025' í¬í•¨ëœ ë…¼ë¬¸ì„ ì‚­ì œ (PT ~ ER ì „ì²´ ì œê±°)\n",
        "filtered_papers = []\n",
        "deleted_count = 0\n",
        "\n",
        "for paper in papers:\n",
        "    if 'PY 2025' in paper:\n",
        "        deleted_count += 1\n",
        "    else:\n",
        "        filtered_papers.append(paper + '\\nER')\n",
        "\n",
        "# 5. ê²°ê³¼ íŒŒì¼ë¡œ ì €ì¥\n",
        "output_filename = 'cleaned_full_removal_2025.txt'\n",
        "with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "    f.write('\\n'.join(filtered_papers))\n",
        "\n",
        "# 6. ê²°ê³¼ ì¶œë ¥\n",
        "print(f'ì´ ë…¼ë¬¸ ìˆ˜: {len(papers)}')\n",
        "print(f'\"PY 2025\" ë…¼ë¬¸ ì‚­ì œ ìˆ˜: {deleted_count}')\n",
        "print(f'ë‚¨ì€ ë…¼ë¬¸ ìˆ˜: {len(filtered_papers)}')\n",
        "\n",
        "# 7. ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ\n",
        "files.download(output_filename)\n"
      ],
      "metadata": {
        "id": "Ol9tFjftlSk0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}